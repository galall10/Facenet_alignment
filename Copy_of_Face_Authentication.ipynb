{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/galall10/Facenet_alignment/blob/main/Copy_of_Face_Authentication.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "ILnqSW7uT7Jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MFRD dataset"
      ],
      "metadata": {
        "id": "33mNmtXspw4h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download MFRD"
      ],
      "metadata": {
        "id": "PLFLEMiMDa0f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaywCfbFBVrU"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "\n",
        "# The Google Drive file ID extracted from your link\n",
        "file_id = '1UlOk6EtiaXTHylRUx2mySgvJX9ycoeBp'\n",
        "\n",
        "# The desired output filename in your Colab environment\n",
        "output_filename = 'downloaded_file'  # MFRD dataset\n",
        "\n",
        "print(f\"Attempting to download file with ID: {file_id}\")\n",
        "try:\n",
        "    # Construct the download URL and use gdown to download\n",
        "    gdown.download(f'https://drive.google.com/uc?id={file_id}', output_filename, quiet=False)\n",
        "    print(f\"File successfully downloaded as: {output_filename}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during download: {e}\")\n",
        "    print(\"Please ensure the file is publicly accessible or shared with 'Anyone with the link'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f36f51a"
      },
      "source": [
        "## Inspect file type\n",
        "\n",
        "### Subtask:\n",
        "Determine the file type of `/content/downloaded_file` to understand how to process it (e.g., if it's a zip archive, a tarball, or another format).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce64e174"
      },
      "source": [
        "**Reasoning**:\n",
        "To determine the file type of `/content/downloaded_file` as per the instruction, I will use the `!file` shell command.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6b716fc"
      },
      "source": [
        "!file /content/downloaded_file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "851d4ce6"
      },
      "source": [
        "## Extract archive (if applicable)\n",
        "\n",
        "### Subtask:\n",
        "If `/content/downloaded_file` is a compressed archive, extract its contents to a new directory.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8db4d2c6"
      },
      "source": [
        "**Reasoning**:\n",
        "Since the previous step identified `/content/downloaded_file` as a Zip archive, the next logical step is to extract its contents. This code block will use the `zipfile` and `os` modules to create an output directory and then extract all files from the archive into it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da8e5108"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define the path to the downloaded file\n",
        "zip_file_path = '/content/downloaded_file'\n",
        "\n",
        "# Define the directory where contents will be extracted\n",
        "extract_dir = '/content/extracted_dataset'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Attempting to extract '{zip_file_path}' to '{extract_dir}'...\")\n",
        "\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "    print(\"File extraction complete.\")\n",
        "    # List contents of the extracted directory to verify\n",
        "    print(\"Contents of extracted_dataset:\")\n",
        "    for item in os.listdir(extract_dir):\n",
        "        print(f\"- {item}\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(f\"Error: '{zip_file_path}' is not a valid Zip file. Skipping extraction.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during extraction: {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8920fc48"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step successfully extracted the archive. Now, to continue exploring the dataset, it's essential to list the contents of the main extracted directory, `self-built-masked-face-recognition-dataset`, to understand its internal structure and locate potential image files.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19c14a67"
      },
      "source": [
        "import os\n",
        "\n",
        "# Define the path to the main extracted dataset directory\n",
        "extracted_root = '/content/extracted_dataset/self-built-masked-face-recognition-dataset'\n",
        "\n",
        "print(f\"Listing contents of '{extracted_root}':\")\n",
        "try:\n",
        "    for item in os.listdir(extracted_root):\n",
        "        print(f\"- {item}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Directory '{extracted_root}' not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while listing directory contents: {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bc325df"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step identified `AFDB_face_dataset` and `AFDB_masked_face_dataset` as subdirectories within the extracted dataset. To find image files, the next step is to recursively list the contents of one of these directories, for example, `AFDB_face_dataset`, to understand its structure and identify where the actual image files are located.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf47bb06"
      },
      "source": [
        "import os\n",
        "\n",
        "# Define the path to one of the potential image directories\n",
        "image_dataset_path = '/content/extracted_dataset/self-built-masked-face-recognition-dataset/AFDB_face_dataset'\n",
        "\n",
        "print(f\"Listing top-level contents of '{image_dataset_path}':\")\n",
        "try:\n",
        "    # List only a few top-level items to avoid overwhelming output if there are many subdirectories/files\n",
        "    contents = os.listdir(image_dataset_path)\n",
        "    for i, item in enumerate(contents):\n",
        "        print(f\"- {item}\")\n",
        "        if i >= 9: # Limit to first 10 items for brevity\n",
        "            print(\"... (and more)\")\n",
        "            break\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Directory '{image_dataset_path}' not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while listing directory contents: {e}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fcc6c93"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step showed that `AFDB_face_dataset` contains subdirectories named after individuals. To find actual image files, I need to list the contents of one of these subdirectories to understand its structure and confirm the presence of images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baa0345d"
      },
      "source": [
        "import os\n",
        "\n",
        "# Choose one of the individual directories to inspect\n",
        "individual_path = os.path.join(image_dataset_path, contents[0]) # Using the first item from the 'contents' list (e.g., 'yangying')\n",
        "\n",
        "print(f\"Listing contents of an individual's directory: '{individual_path}'\")\n",
        "try:\n",
        "    # List a few items from inside an individual's directory\n",
        "    individual_contents = os.listdir(individual_path)\n",
        "    for i, item in enumerate(individual_contents):\n",
        "        print(f\"- {item}\")\n",
        "        if i >= 9: # Limit to first 10 items for brevity\n",
        "            print(\"... (and more)\")\n",
        "            break\n",
        "    if not individual_contents:\n",
        "        print(\"No files found in this directory.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Directory '{individual_path}' not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while listing directory contents: {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fc3cb56"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous steps have confirmed the location and format of image files within the extracted dataset. Now, to complete the task of exploring the dataset, I will collect a few sample image paths and display them using `matplotlib` and `PIL` (Pillow) to visually inspect the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3551658"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Define the directory containing the images (from previous steps)\n",
        "image_directory = individual_path # This is '/content/extracted_dataset/self-built-masked-face-recognition-dataset/AFDB_face_dataset/yangying'\n",
        "\n",
        "# Get a list of all image files in the directory\n",
        "image_files = [os.path.join(image_directory, f) for f in os.listdir(image_directory) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
        "\n",
        "# Limit to a few sample images (e.g., 5 images)\n",
        "sample_images = image_files[:5]\n",
        "\n",
        "print(f\"Displaying {len(sample_images)} sample images from '{image_directory}':\")\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i, img_path in enumerate(sample_images):\n",
        "    try:\n",
        "        img = Image.open(img_path)\n",
        "        plt.subplot(1, len(sample_images), i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(os.path.basename(img_path))\n",
        "        plt.axis('off')\n",
        "    except Exception as e:\n",
        "        print(f\"Could not load image {os.path.basename(img_path)}: {e}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **MFRD csv**"
      ],
      "metadata": {
        "id": "YeKvcUsRqSeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "# ===========================\n",
        "# CONFIGURE AFDB FOLDERS ONLY\n",
        "# ===========================\n",
        "AFDB_DATASETS = {\n",
        "    \"AFDB_face\": \"/content/extracted_dataset/self-built-masked-face-recognition-dataset/AFDB_face_dataset\",\n",
        "    \"AFDB_masked\": \"/content/extracted_dataset/self-built-masked-face-recognition-dataset/AFDB_masked_face_dataset\",\n",
        "}\n",
        "\n",
        "# ===========================\n",
        "# OUTPUT FILES\n",
        "# ===========================\n",
        "MASTER_CSV = \"afdb_master_dataset.csv\"\n",
        "MAP_CSV = \"afdb_person_mapping.csv\"\n",
        "\n",
        "# ===========================\n",
        "# INTERNAL MAPPINGS\n",
        "# ===========================\n",
        "person_to_id = {}\n",
        "next_id = 1\n",
        "master_rows = []\n",
        "\n",
        "def register_person(name):\n",
        "    \"\"\"\n",
        "    Assign a unique numeric ID to each person\n",
        "    \"\"\"\n",
        "    global next_id\n",
        "    if name not in person_to_id:\n",
        "        person_to_id[name] = next_id\n",
        "        next_id += 1\n",
        "    return person_to_id[name]\n",
        "\n",
        "\n",
        "def process_dataset(root_dir, masked_flag, source_name):\n",
        "    \"\"\"\n",
        "    Walk through the AFDB folders:\n",
        "    - image_path\n",
        "    - person_id\n",
        "    - person_name\n",
        "    - masked (0/1)\n",
        "    - source\n",
        "    \"\"\"\n",
        "    for person_name in os.listdir(root_dir):\n",
        "        person_dir = os.path.join(root_dir, person_name)\n",
        "        if not os.path.isdir(person_dir):\n",
        "            continue\n",
        "\n",
        "        person_id = register_person(person_name)\n",
        "\n",
        "        for img_file in os.listdir(person_dir):\n",
        "            img_path = os.path.join(person_dir, img_file)\n",
        "\n",
        "            if not img_file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "                continue\n",
        "\n",
        "            master_rows.append([\n",
        "                img_path,\n",
        "                person_id,\n",
        "                person_name,\n",
        "                masked_flag,\n",
        "                source_name\n",
        "            ])\n",
        "\n",
        "\n",
        "# ===========================\n",
        "# PROCESS AFDB DATASETS ONLY\n",
        "# ===========================\n",
        "process_dataset(AFDB_DATASETS[\"AFDB_face\"], masked_flag=0, source_name=\"AFDB_face\")\n",
        "process_dataset(AFDB_DATASETS[\"AFDB_masked\"], masked_flag=1, source_name=\"AFDB_masked\")\n",
        "\n",
        "# ===========================\n",
        "# WRITE MASTER CSV\n",
        "# ===========================\n",
        "with open(MASTER_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"image_path\", \"person_id\", \"person_name\", \"masked\", \"source\"])\n",
        "    writer.writerows(master_rows)\n",
        "\n",
        "print(f\"AFDB Master dataset saved to {MASTER_CSV}\")\n",
        "\n",
        "# ===========================\n",
        "# WRITE PERSON MAPPING CSV\n",
        "# ===========================\n",
        "with open(MAP_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"person_id\", \"person_name\"])\n",
        "    for name, pid in person_to_id.items():\n",
        "        writer.writerow([pid, name])\n",
        "\n",
        "print(f\"AFDB person mapping saved to {MAP_CSV}\")\n"
      ],
      "metadata": {
        "id": "ZPY4l9foqQ7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **the custom datasets**"
      ],
      "metadata": {
        "id": "oCVuLXfPoNtM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7d76ace"
      },
      "source": [
        "## Process 'Dataset- With mask'\n",
        "\n",
        "### Subtask:\n",
        "Inspect the file type of '/content/Dataset- With mask-20251121T154101Z-1-001.zip' to understand how to process it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92698453"
      },
      "source": [
        "!file /content/Dataset- With mask-20251121T154101Z-1-001.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a70bf07"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to inspect the file type failed because the file path contained spaces and was not properly quoted. I need to re-run the `!file` command, enclosing the file path in double quotes to ensure it is treated as a single argument.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c86820f"
      },
      "source": [
        "!file \"/content/Dataset- With mask-20251121T154101Z-1-001.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a46786ec"
      },
      "source": [
        "## Extract 'Dataset- With mask' archive\n",
        "\n",
        "### Subtask:\n",
        "Extract the contents of '/content/Dataset- With mask-20251121T154101Z-1-001.zip' to a new, dedicated directory.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "841bff20"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step confirmed that '/content/Dataset- With mask-20251121T154101Z-1-001.zip' is a valid Zip archive. Now, I need to extract its contents to a new dedicated directory as instructed. This will involve using `zipfile` to extract and `os` to manage directories and list the contents.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a03b20e"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define the path to the downloaded zip file\n",
        "zip_file_path = '/content/Dataset- With mask-20251121T154101Z-1-001.zip'\n",
        "\n",
        "# Define the new directory where contents will be extracted\n",
        "extract_dir = '/content/dataset_with_mask_extracted'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Attempting to extract '{zip_file_path}' to '{extract_dir}'...\")\n",
        "\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "    print(\"File extraction complete.\")\n",
        "\n",
        "    # List contents of the extracted directory to verify\n",
        "    print(f\"\\nContents of '{extract_dir}':\")\n",
        "    for item in os.listdir(extract_dir):\n",
        "        print(f\"- {item}\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(f\"Error: '{zip_file_path}' is not a valid Zip file. Skipping extraction.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during extraction: {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a77deae"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step successfully extracted the 'Dataset- With mask' archive into `/content/dataset_with_mask_extracted`, revealing a subdirectory named 'Dataset- With mask'. To locate the image files, I need to list the contents of this newly extracted subdirectory to understand its structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "965bbcc3"
      },
      "source": [
        "import os\n",
        "\n",
        "# Define the path to the main extracted dataset directory\n",
        "extracted_masked_root = '/content/dataset_with_mask_extracted/Dataset- With mask'\n",
        "\n",
        "print(f\"Listing contents of '{extracted_masked_root}':\")\n",
        "try:\n",
        "    # List top-level items in the masked dataset directory\n",
        "    contents_masked = os.listdir(extracted_masked_root)\n",
        "    for item in contents_masked:\n",
        "        print(f\"- {item}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Directory '{extracted_masked_root}' not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while listing directory contents: {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7ac6ba4"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step listed the contents of '/content/dataset_with_mask_extracted/Dataset- With mask', showing many subdirectories named after individuals, and also 'train' and 'test_masked'. To find actual image files, I need to list the contents of one of these subdirectories to understand its structure and confirm the presence of images. I will choose 'train' to inspect.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbaf0c89"
      },
      "source": [
        "import os\n",
        "\n",
        "# Define the path to one of the potential image directories (e.g., 'train')\n",
        "image_dataset_path_masked = '/content/dataset_with_mask_extracted/Dataset- With mask/train'\n",
        "\n",
        "print(f\"Listing top-level contents of '{image_dataset_path_masked}':\")\n",
        "try:\n",
        "    # List only a few top-level items to avoid overwhelming output if there are many subdirectories/files\n",
        "    contents_train_masked = os.listdir(image_dataset_path_masked)\n",
        "    for i, item in enumerate(contents_train_masked):\n",
        "        print(f\"- {item}\")\n",
        "        if i >= 9: # Limit to first 10 items for brevity\n",
        "            print(\"... (and more)\")\n",
        "            break\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Directory '{image_dataset_path_masked}' not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while listing directory contents: {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "582ad249"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step showed that the 'train' directory contains subdirectories named after individuals. To find actual image files, I need to list the contents of one of these subdirectories to confirm the presence and format of images. I will choose the first individual's directory from the `contents_train_masked` list for inspection.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a66e220f"
      },
      "source": [
        "import os\n",
        "\n",
        "# Define the path to one of the individual directories within the 'train' folder\n",
        "individual_masked_path = os.path.join(image_dataset_path_masked, contents_train_masked[0]) # e.g., 'Yoshihide Suga'\n",
        "\n",
        "print(f\"Listing contents of an individual's masked directory: '{individual_masked_path}'\")\n",
        "try:\n",
        "    # List a few items from inside an individual's directory\n",
        "    individual_masked_contents = os.listdir(individual_masked_path)\n",
        "    for i, item in enumerate(individual_masked_contents):\n",
        "        print(f\"- {item}\")\n",
        "        if i >= 9: # Limit to first 10 items for brevity\n",
        "            print(\"... (and more)\")\n",
        "            break\n",
        "    if not individual_masked_contents:\n",
        "        print(\"No files found in this directory.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Directory '{individual_masked_path}' not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while listing directory contents: {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63190d93"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous steps have confirmed the location and format of image files within the extracted 'Dataset- With mask' dataset. Now, to continue exploring the dataset, I will collect a few sample image paths from the individual's directory and display them using `matplotlib` and `PIL` (Pillow) to visually inspect the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7a3f436"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Define the directory containing the images (from previous steps)\n",
        "image_directory_masked = individual_masked_path # This is '/content/dataset_with_mask_extracted/Dataset- With mask/train/Yoshihide Suga'\n",
        "\n",
        "# Get a list of all image files in the directory\n",
        "image_files_masked = [os.path.join(image_directory_masked, f) for f in os.listdir(image_directory_masked) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
        "\n",
        "# Limit to a few sample images (e.g., 4 images, as there are only 4 in the example output)\n",
        "sample_images_masked = image_files_masked[:4]\n",
        "\n",
        "print(f\"Displaying {len(sample_images_masked)} sample images from '{image_directory_masked}':\")\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i, img_path in enumerate(sample_images_masked):\n",
        "    try:\n",
        "        img = Image.open(img_path)\n",
        "        plt.subplot(1, len(sample_images_masked), i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(os.path.basename(img_path))\n",
        "        plt.axis('off')\n",
        "    except Exception as e:\n",
        "        print(f\"Could not load image {os.path.basename(img_path)}: {e}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce9407b7"
      },
      "source": [
        "## Process 'Dataset- Without mask'\n",
        "\n",
        "### Subtask:\n",
        "Inspect the file type of '/content/Dataset- Without mask-20251121T154337Z-1-001.zip' to understand how to process it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b979e2d"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the overall task, after processing the 'Dataset- With mask' archive, the next step is to inspect the file type of the second archive, '/content/Dataset- Without mask-20251121T154337Z-1-001.zip', using the `!file` shell command, similar to how the first archive was handled.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5be4b2e"
      },
      "source": [
        "!file \"/content/Dataset- Without mask-20251121T154337Z-1-001.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7988c224"
      },
      "source": [
        "## Extract 'Dataset- Without mask' archive\n",
        "\n",
        "### Subtask:\n",
        "Extract the contents of '/content/Dataset- Without mask-20251121T154337Z-1-001.zip' to a new, dedicated directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f79df94"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step confirmed that '/content/Dataset- Without mask-20251121T154337Z-1-001.zip' is a valid Zip archive. Now, I need to extract its contents to a new dedicated directory as instructed. This will involve using `zipfile` to extract and `os` to manage directories and list the contents.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38fbe345"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define the path to the downloaded zip file\n",
        "zip_file_path_nomask = '/content/Dataset- Without mask-20251121T154337Z-1-001.zip'\n",
        "\n",
        "# Define the new directory where contents will be extracted\n",
        "extract_dir_nomask = '/content/dataset_without_mask_extracted'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_dir_nomask, exist_ok=True)\n",
        "\n",
        "print(f\"Attempting to extract '{zip_file_path_nomask}' to '{extract_dir_nomask}'...\")\n",
        "\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_file_path_nomask, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir_nomask)\n",
        "    print(\"File extraction complete.\")\n",
        "\n",
        "    # List contents of the extracted directory to verify\n",
        "    print(f\"\\nContents of '{extract_dir_nomask}':\")\n",
        "    for item in os.listdir(extract_dir_nomask):\n",
        "        print(f\"- {item}\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(f\"Error: '{zip_file_path_nomask}' is not a valid Zip file. Skipping extraction.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during extraction: {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7f3c2e4"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step successfully extracted the 'Dataset- Without mask' archive into `/content/dataset_without_mask_extracted`, revealing a subdirectory named 'Dataset- Without mask'. To locate the image files, I need to list the contents of this newly extracted subdirectory to understand its structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "87cbddbf"
      },
      "source": [
        "import os\n",
        "\n",
        "# Define the path to the main extracted dataset directory\n",
        "extracted_nomask_root = '/content/dataset_without_mask_extracted/Dataset- Without mask'\n",
        "\n",
        "print(f\"Listing contents of '{extracted_nomask_root}':\")\n",
        "try:\n",
        "    # List top-level items in the unmasked dataset directory\n",
        "    contents_nomask = os.listdir(extracted_nomask_root)\n",
        "    for item in contents_nomask:\n",
        "        print(f\"- {item}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Directory '{extracted_nomask_root}' not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while listing directory contents: {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d878eec9"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step listed the contents of '/content/dataset_without_mask_extracted/Dataset- Without mask', showing many subdirectories named after individuals. To find actual image files, I need to list the contents of one of these subdirectories to confirm the presence and format of images. I will choose the first individual's directory from the `contents_nomask` list for inspection.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "9e9202cd"
      },
      "source": [
        "import os\n",
        "\n",
        "# Define the path to one of the individual directories within the 'Dataset- Without mask' folder\n",
        "individual_nomask_path = os.path.join(extracted_nomask_root, contents_nomask[0]) # e.g., 'Gavin Newsom'\n",
        "\n",
        "print(f\"Listing contents of an individual's unmasked directory: '{individual_nomask_path}'\")\n",
        "try:\n",
        "    # List a few items from inside an individual's directory\n",
        "    individual_nomask_contents = os.listdir(individual_nomask_path)\n",
        "    for i, item in enumerate(individual_nomask_contents):\n",
        "        print(f\"- {item}\")\n",
        "        if i >= 9: # Limit to first 10 items for brevity\n",
        "            print(\"... (and more)\")\n",
        "            break\n",
        "    if not individual_nomask_contents:\n",
        "        print(\"No files found in this directory.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Directory '{individual_nomask_path}' not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while listing directory contents: {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "833314e8"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous steps have confirmed the location and format of image files within the extracted 'Dataset- Without mask' dataset. Now, to continue exploring the dataset, I will collect a few sample image paths from the individual's directory and display them using `matplotlib` and `PIL` (Pillow) to visually inspect the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9695f142"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Define the directory containing the images (from previous steps)\n",
        "image_directory_nomask = individual_nomask_path # This is '/content/dataset_without_mask_extracted/Dataset- Without mask/Gavin Newsom'\n",
        "\n",
        "# Get a list of all image files in the directory\n",
        "image_files_nomask = [os.path.join(image_directory_nomask, f) for f in os.listdir(image_directory_nomask) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
        "\n",
        "# Limit to a few sample images (e.g., 5 images)\n",
        "sample_images_nomask = image_files_nomask[:5]\n",
        "\n",
        "print(f\"Displaying {len(sample_images_nomask)} sample images from '{image_directory_nomask}':\")\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i, img_path in enumerate(sample_images_nomask):\n",
        "    try:\n",
        "        img = Image.open(img_path)\n",
        "        plt.subplot(1, len(sample_images_nomask), i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(os.path.basename(img_path))\n",
        "        plt.axis('off')\n",
        "    except Exception as e:\n",
        "        print(f\"Could not load image {os.path.basename(img_path)}: {e}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9141e95"
      },
      "source": [
        "## Summary for 'Dataset- With mask' and 'Dataset- Without mask':\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   Both '/content/Dataset- With mask-20251121T154101Z-1-001.zip' and '/content/Dataset- Without mask-20251121T154337Z-1-001.zip' were identified as Zip archives.\n",
        "*   They were successfully extracted to their respective dedicated directories: `/content/dataset_with_mask_extracted` and `/content/dataset_without_mask_extracted`.\n",
        "*   Within each extracted directory, a primary folder (`Dataset- With mask` and `Dataset- Without mask`) was found, containing numerous subdirectories named after individuals.\n",
        "*   The 'Dataset- With mask' directory also contained 'train' and 'test_masked' subdirectories, with images organized by individual within the 'train' folder.\n",
        "*   Image files, primarily in `.JPG` format, were found within these individual-named subdirectories for both datasets.\n",
        "*   Sample images from both datasets were successfully loaded and displayed, confirming the accessibility and visual content of the data. Some `.JPG` files were identified as potentially corrupted or not standard image format by PIL, leading to errors during display.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The datasets provide a collection of face images, categorized into 'with mask' and 'without mask', suitable for training and evaluating face detection and recognition models, especially for mask-wearing scenarios.\n",
        "*   The directory structure (individual names as subdirectories) is ideal for tasks like face recognition where unique identities need to be preserved.\n",
        "*   Preprocessing steps such as ensuring all image files are valid and handling potential corruptions (as seen with some `.JPG` files) will be necessary.\n",
        "*   Further steps would involve integrating these datasets into a face detection and alignment pipeline, such as RetinaFace, as outlined in the earlier text cells, for feature extraction and model training."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## custom dataset csv"
      ],
      "metadata": {
        "id": "6p1NoiSdo4mm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "# ===========================\n",
        "# CONFIGURE YOUR FOLDERS HERE\n",
        "# ===========================\n",
        "DATASETS = {\n",
        "    \"unmasked\": \"/content/dataset_without_mask_extracted/Dataset- Without mask\",\n",
        "    \"masked\": \"/content/dataset_with_mask_extracted/Dataset- With mask\",\n",
        "}\n",
        "\n",
        "# ===========================\n",
        "# OUTPUT FILES\n",
        "# ===========================\n",
        "MASTER_CSV = \"master_custom_dataset.csv\"\n",
        "MAP_CSV = \"person_mapping_custom.csv\"\n",
        "\n",
        "# ===========================\n",
        "# INTERNAL MAPPINGS\n",
        "# ===========================\n",
        "person_to_id = {}\n",
        "next_id = 1\n",
        "master_rows = []\n",
        "\n",
        "def register_person(name):\n",
        "    \"\"\"\n",
        "    Assign a unique numeric ID to each person.\n",
        "    \"\"\"\n",
        "    global next_id\n",
        "    if name not in person_to_id:\n",
        "        person_to_id[name] = next_id\n",
        "        next_id += 1\n",
        "    return person_to_id[name]\n",
        "\n",
        "def process_dataset(root_dir, masked_flag, source_name):\n",
        "    \"\"\"\n",
        "    Walk through custom dataset folders:\n",
        "    - image_path\n",
        "    - person_id\n",
        "    - person_name\n",
        "    - masked (0/1)\n",
        "    - source\n",
        "    \"\"\"\n",
        "    for person_name in os.listdir(root_dir):\n",
        "        person_dir = os.path.join(root_dir, person_name)\n",
        "        if not os.path.isdir(person_dir):\n",
        "            continue\n",
        "\n",
        "        person_id = register_person(person_name)\n",
        "\n",
        "        for img_file in os.listdir(person_dir):\n",
        "            img_path = os.path.join(person_dir, img_file)\n",
        "\n",
        "            if not img_file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "                continue\n",
        "\n",
        "            master_rows.append([\n",
        "                img_path,\n",
        "                person_id,\n",
        "                person_name,\n",
        "                masked_flag,\n",
        "                source_name\n",
        "            ])\n",
        "\n",
        "# ===========================\n",
        "# PROCESS CUSTOM DATASETS ONLY\n",
        "# ===========================\n",
        "process_dataset(DATASETS[\"unmasked\"], masked_flag=0, source_name=\"custom_unmasked\")\n",
        "process_dataset(DATASETS[\"masked\"], masked_flag=1, source_name=\"custom_masked\")\n",
        "\n",
        "# ===========================\n",
        "# WRITE MASTER CSV\n",
        "# ===========================\n",
        "with open(MASTER_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"image_path\", \"person_id\", \"person_name\", \"masked\", \"source\"])\n",
        "    writer.writerows(master_rows)\n",
        "\n",
        "print(f\"Master CSV saved to {MASTER_CSV}\")\n",
        "\n",
        "# ===========================\n",
        "# WRITE PERSON MAPPING CSV\n",
        "# ===========================\n",
        "with open(MAP_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"person_id\", \"person_name\"])\n",
        "    for name, pid in person_to_id.items():\n",
        "        writer.writerow([pid, name])\n",
        "\n",
        "print(f\"Person mapping saved to {MAP_CSV}\")\n"
      ],
      "metadata": {
        "id": "QSzbQItpclLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv(\"/content/master_custom_dataset.csv\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DCadol2DcnGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Combined master csv**"
      ],
      "metadata": {
        "id": "pSI_EX25oiIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "from pathlib import Path\n",
        "\n",
        "# ===========================\n",
        "# CONFIGURE YOUR FOLDERS HERE\n",
        "# ===========================\n",
        "DATASETS = {\n",
        "    \"AFDB_face\": \"/content/extracted_dataset/self-built-masked-face-recognition-dataset/AFDB_face_dataset\",\n",
        "    \"AFDB_masked\": \"/content/extracted_dataset/self-built-masked-face-recognition-dataset/AFDB_masked_face_dataset\",\n",
        "\n",
        "    \"custom_unmasked\": \"/content/dataset_without_mask_extracted/Dataset- Without mask\",\n",
        "    \"custom_masked\": \"/content/dataset_with_mask_extracted/Dataset- With mask\",\n",
        "}\n",
        "\n",
        "# ===========================\n",
        "# OUTPUT FILES\n",
        "# ===========================\n",
        "MASTER_CSV = \"master_dataset.csv\"\n",
        "MAP_CSV = \"person_mapping.csv\"\n",
        "\n",
        "# ===========================\n",
        "# INTERNAL MAPPINGS\n",
        "# ===========================\n",
        "person_to_id = {}\n",
        "next_id = 1\n",
        "\n",
        "master_rows = []\n",
        "\n",
        "def register_person(name):\n",
        "    \"\"\"\n",
        "    Assign a unique numeric ID to each person\n",
        "    \"\"\"\n",
        "    global next_id\n",
        "    if name not in person_to_id:\n",
        "        person_to_id[name] = next_id\n",
        "        next_id += 1\n",
        "    return person_to_id[name]\n",
        "\n",
        "\n",
        "def process_dataset(root_dir, masked_flag, source_name):\n",
        "    \"\"\"\n",
        "    Walk through a dataset folder and extract:\n",
        "    - image_path\n",
        "    - person_id\n",
        "    - person_name\n",
        "    - masked (0/1)\n",
        "    - source\n",
        "    \"\"\"\n",
        "    for person_name in os.listdir(root_dir):\n",
        "        person_dir = os.path.join(root_dir, person_name)\n",
        "        if not os.path.isdir(person_dir):\n",
        "            continue\n",
        "\n",
        "        person_id = register_person(person_name)\n",
        "\n",
        "        for img_file in os.listdir(person_dir):\n",
        "            img_path = os.path.join(person_dir, img_file)\n",
        "\n",
        "            if not img_file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "                continue\n",
        "\n",
        "            master_rows.append([\n",
        "                img_path,\n",
        "                person_id,\n",
        "                person_name,\n",
        "                masked_flag,\n",
        "                source_name\n",
        "            ])\n",
        "\n",
        "\n",
        "# ===========================\n",
        "# PROCESS ALL DATASETS\n",
        "# ===========================\n",
        "process_dataset(DATASETS[\"AFDB_face\"], masked_flag=0, source_name=\"AFDB_face\")\n",
        "process_dataset(DATASETS[\"AFDB_masked\"], masked_flag=1, source_name=\"AFDB_masked\")\n",
        "\n",
        "process_dataset(DATASETS[\"custom_unmasked\"], masked_flag=0, source_name=\"custom_unmasked\")\n",
        "process_dataset(DATASETS[\"custom_masked\"], masked_flag=1, source_name=\"custom_masked\")\n",
        "\n",
        "# ===========================\n",
        "# WRITE MASTER CSV\n",
        "# ===========================\n",
        "with open(MASTER_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"image_path\", \"person_id\", \"person_name\", \"masked\", \"source\"])\n",
        "    writer.writerows(master_rows)\n",
        "\n",
        "print(f\"Master dataset saved to {MASTER_CSV}\")\n",
        "\n",
        "# ===========================\n",
        "# WRITE PERSON MAPPING CSV\n",
        "# ===========================\n",
        "with open(MAP_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"person_id\", \"person_name\"])\n",
        "    for name, pid in person_to_id.items():\n",
        "        writer.writerow([pid, name])\n",
        "\n",
        "print(f\"Person mapping saved to {MAP_CSV}\")\n"
      ],
      "metadata": {
        "id": "K_RjDAIpR_8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_df = pd.read_csv(\"/content/master_dataset.csv\")\n",
        "master_mapping = pd.read_csv(\"/content/person_mapping.csv\")"
      ],
      "metadata": {
        "id": "X-eoiJamHHnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_df.head()"
      ],
      "metadata": {
        "id": "lp-ix9VkHQDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master_mapping.head()"
      ],
      "metadata": {
        "id": "GIrVVwdBHUgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **detect_and_align_Faces**"
      ],
      "metadata": {
        "id": "DHQh__83K_ap"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Face Detection & Alignment\n",
        "\n",
        "\n",
        "* Crop face\n",
        "\n",
        "* Align using 5 facial landmarks\n",
        "\n",
        "* Resize to 112Ã—112\n",
        "\n",
        "* Normalize\n",
        "\n"
      ],
      "metadata": {
        "id": "S3Xyj18NLLk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  -q mediapipe==0.10.14 opencv-python numpy tqdm"
      ],
      "metadata": {
        "collapsed": true,
        "id": "w-lxTybJ9GXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O face_landmarker.task \\\n",
        "\"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\"\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7QEsXMiIBLyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapipe as mp\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "BaseOptions = python.BaseOptions\n",
        "FaceLandmarker = vision.FaceLandmarker\n",
        "FaceLandmarkerOptions = vision.FaceLandmarkerOptions\n",
        "RunningMode = vision.RunningMode\n",
        "\n",
        "options = FaceLandmarkerOptions(\n",
        "    base_options=BaseOptions(model_asset_path=\"face_landmarker.task\"),\n",
        "    running_mode=RunningMode.IMAGE,\n",
        "    num_faces=1\n",
        ")\n",
        "\n",
        "landmarker = FaceLandmarker.create_from_options(options)\n",
        "\n"
      ],
      "metadata": {
        "id": "vAV06GqI9Om9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def align_face_mediapipe(img_bgr):\n",
        "    img = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "    mp_img = mp.Image(image_format=mp.ImageFormat.SRGB, data=img)\n",
        "\n",
        "    result = landmarker.detect(mp_img)\n",
        "    if not result.face_landmarks:\n",
        "        return None  # no face detected\n",
        "\n",
        "    ln = result.face_landmarks[0]\n",
        "    h, w, _ = img_bgr.shape\n",
        "\n",
        "    pts = np.array([[lm.x * w, lm.y * h] for lm in ln], dtype=np.float32)\n",
        "\n",
        "    # Eye indices (MediaPipe Mesh)\n",
        "    left_eye  = pts[468]\n",
        "    right_eye = pts[473]\n",
        "\n",
        "    # Compute alignment\n",
        "    dx = right_eye[0] - left_eye[0]\n",
        "    dy = right_eye[1] - left_eye[1]\n",
        "    angle = np.degrees(np.arctan2(dy, dx))\n",
        "    center = ((left_eye[0] + right_eye[0]) / 2,\n",
        "              (left_eye[1] + right_eye[1]) / 2)\n",
        "\n",
        "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "    rotated = cv2.warpAffine(img_bgr, M, (w, h))\n",
        "\n",
        "    # Crop around center (224x224 then resize)\n",
        "    x, y = int(center[0]), int(center[1])\n",
        "    crop_size = 200\n",
        "\n",
        "    x1, y1 = max(0, x - crop_size//2), max(0, y - crop_size//2)\n",
        "    x2, y2 = min(w, x + crop_size//2), min(h, y + crop_size//2)\n",
        "    cropped = rotated[y1:y2, x1:x2]\n",
        "\n",
        "    if cropped.size == 0:\n",
        "        return None\n",
        "\n",
        "    aligned = cv2.resize(cropped, (112, 112))\n",
        "    return aligned\n"
      ],
      "metadata": {
        "id": "NKeoR0YG_R16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "img = cv2.imread(\"/content/04.JPG\")\n",
        "aligned = align_face_mediapipe(img)\n",
        "\n",
        "if aligned is None:\n",
        "    print(\"âŒ No face detected\")\n",
        "else:\n",
        "    print(\"Aligned shape:\", aligned.shape)\n",
        "    cv2.imwrite(\"aligned_example.jpg\", aligned)\n",
        "\n",
        "    # Show the result\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.imshow(cv2.cvtColor(aligned, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "eSZsjMR6Rhnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/master_custom_dataset.csv\")\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "5LrrPzPZTM5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "OUTPUT_DIR = \"/content/aligned_dataset\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "EfumT_ubTQ13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Aligning Dataset\"):\n",
        "    img_path = row[\"image_path\"]\n",
        "    person_name = row[\"person_name\"]  # safer than using folder name\n",
        "\n",
        "    # output folder: /aligned_dataset/person_name/\n",
        "    out_dir = os.path.join(OUTPUT_DIR, person_name)\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    # read image\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        print(\"âŒ Failed to read:\", img_path)\n",
        "        continue\n",
        "\n",
        "    aligned = align_face_mediapipe(img)\n",
        "    if aligned is None:\n",
        "        print(\"âŒ No face:\", img_path)\n",
        "        continue\n",
        "\n",
        "    # output file â€” keep original filename\n",
        "    file_name = os.path.basename(img_path)\n",
        "    out_path = os.path.join(out_dir, file_name)\n",
        "    cv2.imwrite(out_path, aligned)\n"
      ],
      "metadata": {
        "id": "5QYBadGhRs1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data loader\n"
      ],
      "metadata": {
        "id": "sumcAYTmYPwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q facenet-pytorch"
      ],
      "metadata": {
        "id": "tgHO5PT4YbUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
      ],
      "metadata": {
        "id": "8IordgNRZiLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as T\n",
        "\n",
        "class FaceNetDataset(Dataset):\n",
        "    def __init__(self, root):\n",
        "        self.root = root\n",
        "        self.samples = []\n",
        "        self.person_to_id = {}\n",
        "        pid = 0\n",
        "\n",
        "        for person_name in os.listdir(root):\n",
        "            person_path = os.path.join(root, person_name)\n",
        "            if not os.path.isdir(person_path):\n",
        "                continue\n",
        "\n",
        "            self.person_to_id[person_name] = pid\n",
        "            pid += 1\n",
        "\n",
        "            for img_file in os.listdir(person_path):\n",
        "                if img_file.lower().endswith((\"jpg\", \"jpeg\", \"png\")):\n",
        "                    self.samples.append((os.path.join(person_path, img_file), self.person_to_id[person_name]))\n",
        "\n",
        "        # Facenet-pytorch expects 160x160!\n",
        "        self.transform = T.Compose([\n",
        "            T.Resize((160, 160)),  # <-- This solves your problem\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "        ])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, pid = self.samples[idx]\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        img = self.transform(img)\n",
        "        return img, pid\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n"
      ],
      "metadata": {
        "id": "zjcDQ4MjWDBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from facenet_pytorch import InceptionResnetV1\n",
        "\n",
        "from facenet_pytorch import InceptionResnetV1\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Load FaceNet\n",
        "model = InceptionResnetV1(pretrained='vggface2', classify=False)\n",
        "model = model.cuda()\n",
        "\n",
        "# FIX for BatchNorm training with batch size 1\n",
        "model.eval()      # <-- ADD THIS\n",
        "\n",
        "# Define loss\n",
        "triplet_loss = torch.nn.TripletMarginLoss(margin=1.0, p=2)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4nzl0N3JeaaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def sample_triplet(dataset):\n",
        "    # choose anchor\n",
        "    anchor_idx = random.randint(0, len(dataset)-1)\n",
        "    anchor_img, anchor_id = dataset[anchor_idx]\n",
        "\n",
        "    # choose positive (same person)\n",
        "    while True:\n",
        "        pos_idx = random.randint(0, len(dataset)-1)\n",
        "        pos_img, pos_id = dataset[pos_idx]\n",
        "        if pos_id == anchor_id:\n",
        "            break\n",
        "\n",
        "    # choose negative (different person)\n",
        "    while True:\n",
        "        neg_idx = random.randint(0, len(dataset)-1)\n",
        "        neg_img, neg_id = dataset[neg_idx]\n",
        "        if neg_id != anchor_id:\n",
        "            break\n",
        "\n",
        "    return anchor_img, pos_img, neg_img\n",
        "\n"
      ],
      "metadata": {
        "id": "5Z_u30oxezxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_triplet(model, dataset, epochs=10, steps_per_epoch=2000):\n",
        "    model.eval()  # <-- KEEP model in eval mode\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "\n",
        "        for step in range(steps_per_epoch):\n",
        "            a, p, n = sample_triplet(dataset)\n",
        "            a, p, n = a.cuda().unsqueeze(0), p.cuda().unsqueeze(0), n.cuda().unsqueeze(0)\n",
        "\n",
        "            emb_a = model(a)\n",
        "            emb_p = model(p)\n",
        "            emb_n = model(n)\n",
        "\n",
        "            loss = triplet_loss(emb_a, emb_p, emb_n)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} â€” Loss: {total_loss/steps_per_epoch:.4f}\")\n"
      ],
      "metadata": {
        "id": "ajk4VnGYe2Tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_bn_eval(m):\n",
        "    if isinstance(m, torch.nn.BatchNorm2d) or isinstance(m, torch.nn.BatchNorm1d):\n",
        "        m.eval()\n",
        "\n",
        "model = InceptionResnetV1(pretrained='vggface2', classify=False).cuda()\n",
        "model.train()\n",
        "model.apply(set_bn_eval)  # freeze BN\n"
      ],
      "metadata": {
        "id": "KCNYWCuluTVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import random\n",
        "\n",
        "class TripletDataset(Dataset):\n",
        "    def __init__(self, dataset, batch_size=32):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # build index per person\n",
        "        self.person_index = {}\n",
        "        for idx, (_, pid) in enumerate(dataset.samples):\n",
        "            self.person_index.setdefault(pid, []).append(idx)\n",
        "\n",
        "        # list of all IDs\n",
        "        self.ids = list(self.person_index.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return 100000  # infinite sampling\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        a_id = random.choice(self.ids)\n",
        "        pos_id = a_id\n",
        "        neg_id = random.choice([i for i in self.ids if i != a_id])\n",
        "\n",
        "        a_idx, p_idx = random.sample(self.person_index[a_id], 2)\n",
        "        n_idx = random.choice(self.person_index[neg_id])\n",
        "\n",
        "        a_img, _ = self.dataset[a_idx]\n",
        "        p_img, _ = self.dataset[p_idx]\n",
        "        n_img, _ = self.dataset[n_idx]\n",
        "\n",
        "        return a_img, p_img, n_img\n",
        "\n",
        "triplet_loader = DataLoader(TripletDataset(dataset), batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "TUaTIcxMuWSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "triplet_loss = nn.TripletMarginLoss(margin=1, p=2)\n",
        "\n",
        "def train(model, loader, epochs=10):\n",
        "    model.train()\n",
        "    model.apply(set_bn_eval)  # keep BN frozen\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        pbar = tqdm(loader, total=300)  # 300 batches per epoch\n",
        "        total_loss = 0\n",
        "\n",
        "        for a, p, n in pbar:\n",
        "            a, p, n = a.cuda(), p.cuda(), n.cuda()\n",
        "\n",
        "            emb_a = model(a)\n",
        "            emb_p = model(p)\n",
        "            emb_n = model(n)\n",
        "\n",
        "            loss = triplet_loss(emb_a, emb_p, emb_n)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            pbar.set_description(f\"Epoch {epoch+1}, Loss={loss.item():.4f}\")\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Mean Loss = {total_loss/300:.4f}\")\n"
      ],
      "metadata": {
        "id": "yQ8-8KsIuZE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = FaceNetDataset(\"/content/aligned_dataset\")\n",
        "train(model, triplet_loader, epochs=10)"
      ],
      "metadata": {
        "id": "fjhk2k3cWLU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"current_facenet_backup.pth\")\n",
        "print(\"âœ” Model saved!\")\n"
      ],
      "metadata": {
        "id": "Naoxc6Us7lju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from facenet_pytorch import InceptionResnetV1\n",
        "import torch\n",
        "\n",
        "model = InceptionResnetV1(pretrained='vggface2', classify=False)\n",
        "model.load_state_dict(torch.load(\"current_facenet_backup.pth\"))\n",
        "model = model.cuda()\n",
        "model.eval()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ioLQagsG8Jlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "XP3cOEwgDE8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/afdb_master_dataset.csv\")"
      ],
      "metadata": {
        "id": "ZHLqeO_VCzcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "LprTj7CJDOBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_rmfd = df[df['source'].isin(['AFDB_face', 'AFDB_masked'])]\n",
        "print(len(df_rmfd))\n",
        "\n"
      ],
      "metadata": {
        "id": "kgtG_-vzDc8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def sample_person_group(df, percent=0.05):\n",
        "    samples = []\n",
        "    for pid, group in df.groupby([\"person_id\", \"masked\"]):\n",
        "        k = max(1, int(len(group) * percent))\n",
        "        samples.append(group.sample(k, random_state=42))\n",
        "    return pd.concat(samples)\n",
        "\n",
        "df_test = sample_person_group(df_rmfd, percent=0.05)\n",
        "print(len(df_test))\n"
      ],
      "metadata": {
        "id": "RvDombWWDhoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import mediapipe as mp\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load MediaPipe Landmarker\n",
        "BaseOptions = python.BaseOptions\n",
        "FaceLandmarker = vision.FaceLandmarker\n",
        "FaceLandmarkerOptions = vision.FaceLandmarkerOptions\n",
        "RunningMode = vision.RunningMode\n",
        "\n",
        "options = FaceLandmarkerOptions(\n",
        "    base_options=BaseOptions(model_asset_path=\"face_landmarker.task\"),\n",
        "    running_mode=RunningMode.IMAGE,\n",
        "    num_faces=1\n",
        ")\n",
        "\n",
        "landmarker = FaceLandmarker.create_from_options(options)\n",
        "\n",
        "def align_face_mediapipe(img_bgr):\n",
        "    img = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "    mp_img = mp.Image(image_format=mp.ImageFormat.SRGB, data=img)\n",
        "\n",
        "    result = landmarker.detect(mp_img)\n",
        "    if not result.face_landmarks:\n",
        "        return None  # no face detected\n",
        "\n",
        "    ln = result.face_landmarks[0]\n",
        "    h, w, _ = img_bgr.shape\n",
        "\n",
        "    pts = np.array([[lm.x * w, lm.y * h] for lm in ln], dtype=np.float32)\n",
        "\n",
        "    # Eye landmarks (MediaPipe face mesh)\n",
        "    left_eye  = pts[468]\n",
        "    right_eye = pts[473]\n",
        "\n",
        "    dx = right_eye[0] - left_eye[0]\n",
        "    dy = right_eye[1] - left_eye[1]\n",
        "    angle = np.degrees(np.arctan2(dy, dx))\n",
        "    center = ((left_eye[0] + right_eye[0]) / 2,\n",
        "              (left_eye[1] + right_eye[1]) / 2)\n",
        "\n",
        "    # Rotate image\n",
        "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "    rotated = cv2.warpAffine(img_bgr, M, (w, h))\n",
        "\n",
        "    # Crop around eyes\n",
        "    crop_size = 200\n",
        "    x, y = int(center[0]), int(center[1])\n",
        "\n",
        "    x1, y1 = max(0, x - crop_size // 2), max(0, y - crop_size // 2)\n",
        "    x2, y2 = min(w, x + crop_size // 2), min(h, y + crop_size // 2)\n",
        "\n",
        "    cropped = rotated[y1:y2, x1:x2]\n",
        "\n",
        "    if cropped.size == 0:\n",
        "        return None\n",
        "\n",
        "    # FaceNet required size\n",
        "    aligned = cv2.resize(cropped, (160, 160))\n",
        "    return aligned\n"
      ],
      "metadata": {
        "id": "ehjsR002DuTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = sample_person_group(df_rmfd, percent=0.05)"
      ],
      "metadata": {
        "id": "OgWfpPfWEArX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "TEST_ALIGN_DIR = \"/content/rmfd_test_aligned\"\n",
        "os.makedirs(TEST_ALIGN_DIR, exist_ok=True)\n",
        "\n",
        "aligned_paths = []\n",
        "\n",
        "for idx, row in tqdm(df_test.iterrows(), total=len(df_test)):\n",
        "    img = cv2.imread(row[\"image_path\"])\n",
        "    if img is None:\n",
        "        continue\n",
        "\n",
        "    aligned = align_face_mediapipe(img)\n",
        "    if aligned is None:\n",
        "        continue\n",
        "\n",
        "    # save path mimics folder structure\n",
        "    save_path = row[\"image_path\"].replace(\"/content/extracted_dataset\", TEST_ALIGN_DIR)\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "    cv2.imwrite(save_path, aligned)\n",
        "\n",
        "    aligned_paths.append((save_path, row[\"person_id\"], row[\"masked\"]))\n"
      ],
      "metadata": {
        "id": "pCY65dDnDkxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aligned_paths.append((save_path, row[\"person_id\"], row[\"masked\"]))"
      ],
      "metadata": {
        "id": "05siiM3fE4jR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_aligned = pd.DataFrame(aligned_paths, columns=[\"aligned_path\", \"person_id\", \"masked\"])\n",
        "df_aligned.head()\n"
      ],
      "metadata": {
        "id": "WIegs_aQE5yM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from facenet_pytorch import InceptionResnetV1\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Initialize the same model architecture used in training\n",
        "model = InceptionResnetV1(pretrained=None, classify=False)\n",
        "\n",
        "# Load checkpoint weights (ignore classifier layer)\n",
        "state = torch.load(\"current_facenet_backup.pth\", weights_only=True)\n",
        "model.load_state_dict(state, strict=False)\n",
        "\n",
        "model = model.cuda()\n",
        "model.eval()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Kw-rbAhDE7ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.Resize((160, 160)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5]),\n",
        "])\n",
        "\n",
        "def get_embedding(path):\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    img = transform(img).unsqueeze(0).cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        emb = model(img)\n",
        "    return emb.cpu()\n"
      ],
      "metadata": {
        "id": "_jdcnWnhFkuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/rmfd_test_aligned -maxdepth 3 -type f | head -20"
      ],
      "metadata": {
        "id": "io5UL4kxF6fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "emb1 = get_embedding(\"/content/aligned_dataset/Abdelfattah Elsisi/01.JPG\")\n",
        "emb2 = get_embedding(\"/content/aligned_dataset/Abdelfattah Elsisi/02.jpg\")\n",
        "\n",
        "distance = F.pairwise_distance(emb1, emb2).item()\n",
        "\n",
        "print(\"Distance:\", distance)\n",
        "\n",
        "if distance < 1.0:\n",
        "    print(\"âœ” Same person\")\n",
        "else:\n",
        "    print(\"âŒ Different person\")\n"
      ],
      "metadata": {
        "id": "L9zXekq_FmPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "emb1 = get_embedding(\"/content/ali rabi3 kmama.png\")\n",
        "emb2 = get_embedding(\"/content/ali rabi3.jpg\")\n",
        "\n",
        "distance = F.pairwise_distance(emb1, emb2).item()\n",
        "\n",
        "print(\"Distance:\", distance)\n",
        "\n",
        "if distance < 1.0:\n",
        "    print(\"âœ” Same person\")\n",
        "else:\n",
        "    print(\"âŒ Different person\")\n"
      ],
      "metadata": {
        "id": "AeAOcS1FJxad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "-gWkc7dEGdp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/current_facenet_backup.pth /content/drive/MyDrive/current_facenet_backup.pth\n"
      ],
      "metadata": {
        "id": "RAqkRHTwGiGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding"
      ],
      "metadata": {
        "id": "x5fIxgeOIc1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "\n",
        "# FaceNet input pipeline â€” 160Ã—160 normalized\n",
        "transform_160 = T.Compose([\n",
        "    T.Resize((160, 160)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.5]*3, [0.5]*3),\n",
        "])\n",
        "\n",
        "def get_embedding_from_pil(pil_img):\n",
        "    \"\"\"\n",
        "    Convert aligned PIL image to FaceNet embedding tensor (512-dim).\n",
        "    \"\"\"\n",
        "    img_t = transform_160(pil_img).unsqueeze(0).cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        emb = model(img_t).cpu().squeeze()\n",
        "\n",
        "    return emb\n"
      ],
      "metadata": {
        "id": "uC8DnejlIcEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "df = pd.read_csv(\"/content/master_custom_dataset.csv\")\n",
        "\n",
        "embedding_db = {}\n",
        "\n",
        "print(\"ðŸš€ Building embedding database...\")\n",
        "\n",
        "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "\n",
        "    img_path = row[\"image_path\"]\n",
        "    person_id = row[\"person_id\"]\n",
        "    person_name = row[\"person_name\"]\n",
        "\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        continue\n",
        "\n",
        "    # Align the face\n",
        "    aligned = align_face_mediapipe(img)\n",
        "    if aligned is None:\n",
        "        continue\n",
        "\n",
        "    aligned = cv2.cvtColor(aligned, cv2.COLOR_BGR2RGB)\n",
        "    aligned_pil = Image.fromarray(aligned)\n",
        "\n",
        "    # Convert aligned face â†’ embedding\n",
        "    emb = get_embedding_from_pil(aligned_pil)\n",
        "\n",
        "    # Add to DB\n",
        "    if person_id not in embedding_db:\n",
        "        embedding_db[person_id] = {\"name\": person_name, \"embeddings\": []}\n",
        "\n",
        "    embedding_db[person_id][\"embeddings\"].append(emb)\n",
        "\n",
        "print(\"âœ” Done! Embedding database complete.\")\n",
        "print(f\"Total Persons = {len(embedding_db)}\")\n",
        "\n",
        "# Optional save\n",
        "torch.save(embedding_db, \"embedding_database.pt\")"
      ],
      "metadata": {
        "id": "IXuOTPIpMQo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def identify_person(img_path, threshold=0.95):\n",
        "    \"\"\"\n",
        "    Given an image path â†’ align â†’ embed â†’ compare â†’ return best match.\n",
        "    \"\"\"\n",
        "    # Load image\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"âŒ Cannot read image: {img_path}\")\n",
        "\n",
        "    # Align face\n",
        "    aligned = align_face_mediapipe(img)\n",
        "    if aligned is None:\n",
        "        return \"Unknown\", None\n",
        "\n",
        "    aligned = cv2.cvtColor(aligned, cv2.COLOR_BGR2RGB)\n",
        "    aligned_pil = Image.fromarray(aligned)\n",
        "\n",
        "    # Convert to embedding\n",
        "    query_emb = get_embedding_from_pil(aligned_pil)\n",
        "\n",
        "    best_name = \"Unknown\"\n",
        "    best_dist = 999\n",
        "\n",
        "    # Search the embedding DB\n",
        "    for pid, entry in embedding_db.items():\n",
        "        person_name = entry[\"name\"]\n",
        "        embeddings = entry[\"embeddings\"]\n",
        "\n",
        "        # Compute min distance to this person's stored embeddings\n",
        "        dists = [F.pairwise_distance(query_emb.unsqueeze(0),\n",
        "                                     emb.unsqueeze(0)).item()\n",
        "                 for emb in embeddings]\n",
        "\n",
        "        person_dist = min(dists)\n",
        "\n",
        "        if person_dist < best_dist:\n",
        "            best_dist = person_dist\n",
        "            best_name = person_name\n",
        "\n",
        "    # Apply threshold\n",
        "    if best_dist > threshold:\n",
        "        return \"Unknown\", best_dist\n",
        "\n",
        "    return best_name, best_dist\n"
      ],
      "metadata": {
        "id": "iE_TcbW5OwVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name, dist = identify_person(\"/content/adele-attends-the-brit-awards-2022-at-the-o2-arena-on-news-photo-1709739132.avif\")\n",
        "print(name, dist)"
      ],
      "metadata": {
        "id": "G7YGKNukOUzx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}